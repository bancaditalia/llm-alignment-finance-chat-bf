{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting logistic regression models to interpret LLM decision making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and define some constants \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import linregress\n",
    "\n",
    "models_ordered = [\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"gpt-4-turbo\",\n",
    "    \"claude-3-haiku\",\n",
    "    \"claude-sonnet-3.5\",\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"llama3.1\",\n",
    "    \"phi3.5-mini\",\n",
    "    \"o1-mini\",\n",
    "    \"o1-preview\",\n",
    "]\n",
    "\n",
    "MMLUs = {'o1-preview': 91, \n",
    "          'gpt-4o': 88.7, \n",
    "          'gpt-4-turbo': 87,\n",
    "          'o1-mini': 85,\n",
    "          'gpt-4o-mini': 82, \n",
    "          'llama3.1': 73.0,\n",
    "          'gpt-3.5-turbo': 68,\n",
    "          \"claude-3-haiku\": 75.2,\n",
    "          \"claude-sonnet-3.5\": 88.7,\n",
    "          \"phi3.5-mini\": 69,\n",
    "          }\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "color_table = {model: color for model, color in zip(models_ordered, colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cur_dir = os.getcwd() \n",
    "os.chdir(cur_dir.replace(\"notebooks\", \"\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "### NOTE: please download the .csv files from the dropbox folder (see link in the README). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and standardize the data\n",
    "\n",
    "df = pd.read_csv(\"data/simulation_results/pressure_variables_alignment.csv\") \n",
    "\n",
    "# drop columns that are not needed\n",
    "df = df.drop(columns=[\"sim_id\", \"spec_ID\"])\n",
    "\n",
    "# convert categorical variables to numerical depending on the expected direction of the effect\n",
    "conversion_table = {\"trust_\": {np.nan: 0.0, \"High\": 1.0, \"Low\": -1.0},\n",
    "                    \"risk_\": { np.nan: 0.0, \"High\": -1.0, \"Low\": 1.0},\n",
    "                    \"reg_\": {np.nan: 0.0, \"Unregulated\": -1.0, \"Regulated\": 1.0},\n",
    "                    \"gov_\": {np.nan: 0.0, \"Bad\": -1.0, \"Good\": 1.0},\n",
    "                    \"outlook_\": {np.nan: 0.0, \"Pessimistic\": -1, \"Optimistic\": 1},\n",
    "                    \"profit_exp\": {np.nan: 0.0, \"low\": -1.0, \"high\": 1.0},\n",
    "                    \"loan\": {150000: +1.0, 270000: -1.0, 30000: 0.0}\n",
    "                   }\n",
    "df = df.replace(conversion_table)\n",
    "\n",
    "# select temp_ = 1.0 results\n",
    "df = df[df[\"temp_\"] == 1.0]\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a transformation to a \"one hot\" representation with an intercept\n",
    "def transform_X(X):\n",
    "    X_transformed = np.ones((X.shape[0], X.shape[1] * 2))*999\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if X[i, j] == 0:\n",
    "                X_transformed[i, 2*j] = 0\n",
    "                X_transformed[i, 2*j + 1] = 0\n",
    "            elif X[i, j] == 1:\n",
    "                X_transformed[i, 2*j] = 1\n",
    "                X_transformed[i, 2*j + 1] = 0\n",
    "            elif X[i, j] == -1:\n",
    "                X_transformed[i, 2*j] = 0\n",
    "                X_transformed[i, 2*j + 1] = 1\n",
    "\n",
    "    assert X_transformed.max() == 1\n",
    "    \n",
    "    # add a column of ones for the intercept\n",
    "    X_transformed = np.concatenate([X_transformed, np.ones((X_transformed.shape[0], 1))], axis=1)\n",
    "    \n",
    "    return X_transformed\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries with plain numerical data to be used in the regressions\n",
    "Xs_dict = {}\n",
    "ys_dict = {}\n",
    "rs_dict = {}\n",
    "\n",
    "for model in models_ordered:\n",
    "    print(model)\n",
    "    df_model = df[(df['model_'] == model)]\n",
    "    df_model = df_model.drop(columns=['model_'])\n",
    "    \n",
    "    df_X = df_model.drop(columns=['misal_', 'resp', 'temp_'])\n",
    "    X = df_X.to_numpy()\n",
    "    X = transform_X(X)\n",
    "    y = df_model['misal_'].to_numpy()\n",
    "    r = df_model['resp'].to_numpy()\n",
    "    \n",
    "    Xs_dict[model] = X\n",
    "    ys_dict[model] = y\n",
    "    rs_dict[model] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic regressions on all models and store the results in a dictionary\n",
    "results_dict = {}\n",
    "\n",
    "for model in models_ordered:\n",
    "    print(model)\n",
    "    X = Xs_dict[model]\n",
    "    y = ys_dict[model]\n",
    "    \n",
    "    # fit the model\n",
    "    logit_mod = sm.Logit(y, X)\n",
    "    result = logit_mod.fit()\n",
    "    results_dict[model] = {}\n",
    "    results_dict[model][\"summary\"] = result.summary()\n",
    "    results_dict[model][\"params\"] = result.params\n",
    "    results_dict[model][\"params_errs\"] = result.bse\n",
    "    results_dict[model][\"odds_ratios\"] = np.exp(result.params)\n",
    "    results_dict[model][\"pvalues\"] = result.pvalues\n",
    "    results_dict[model][\"pseudo_r2\"] = result.prsquared\n",
    "    results_dict[model][\"N\"] = result.nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary results for each model\n",
    "for model in models_ordered:\n",
    "    print(model)\n",
    "    print(results_dict[model][\"summary\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export odds ratios to a csv file\n",
    "X_labels = [\"risk+\", \"risk-\", \"reg+\", \"reg-\", \"loan+\", \"loan-\", \"gov+\", \"gov-\", \"trust+\", \"trust-\", \"outlook+\", \"outlook-\", \"profitexp+\", \"profitexp-\", \"constant\"]\n",
    "\n",
    "# odds ratio\n",
    "results_df = pd.DataFrame(columns=['model'] + X_labels)\n",
    "temp = 1\n",
    "\n",
    "for model in models_ordered:\n",
    "    results = results_dict[model]\n",
    "    row = [model]\n",
    "    for or_, err, pval in zip(results[\"odds_ratios\"], results[\"params_errs\"], results[\"pvalues\"]):\n",
    "        row.append(or_)\n",
    "    results_df.loc[len(results_df)] = row\n",
    "\n",
    "results_df.to_csv(\"data/simulation_results/odds_ratios.csv\", index=False)\n",
    "\n",
    "## p-values\n",
    "results_df = pd.DataFrame(columns=['model'] + X_labels)\n",
    "temp = 1\n",
    "\n",
    "for model in models_ordered:\n",
    "    results = results_dict[model]\n",
    "    row = [model]\n",
    "    for or_, err, pval in zip(results[\"odds_ratios\"], results[\"params_errs\"], results[\"pvalues\"]):\n",
    "        row.append(pval)\n",
    "    results_df.loc[len(results_df)] = row\n",
    "\n",
    "results_df.to_csv(\"data/simulation_results/pvalues.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation of R2s with MMLUs\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "for model in models_ordered:\n",
    "    \n",
    "    color = color_table[model]\n",
    "    r2s = results_dict[model][\"pseudo_r2\"]  \n",
    "    \n",
    "    MMLU = MMLUs[model]\n",
    "    \n",
    "    plt.scatter(MMLU, r2s, label=model, s = 100, color = color)\n",
    "    \n",
    "plt.xlabel('MMLU' + r'$\\uparrow$')   \n",
    "plt.ylabel('pseudo-R2'  + r'$\\uparrow$')\n",
    "    \n",
    "# get all MMLU, pseudo-R2 pairs\n",
    "MMLUs_ = [MMLUs[model] for model in models_ordered]\n",
    "R2s = [results_dict[model][\"pseudo_r2\"] for model in models_ordered]\n",
    "\n",
    "# fit a line using scipy.stats.linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(MMLUs_, R2s)\n",
    "\n",
    "print(slope, intercept, r_value, p_value, std_err)\n",
    "\n",
    "# plot the line\n",
    "xs = np.linspace(65, 95, 100)\n",
    "ys = slope * xs + intercept\n",
    "plt.plot(xs, ys, color = 'black', linestyle = '--', label = \"p-value = {:.3f}\".format(p_value))\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reactivity of all models to overall pressure\n",
    "\n",
    "plt.figure(figsize=(5.5, 3))\n",
    "\n",
    "for model in models_ordered:\n",
    "    \n",
    "    X = Xs_dict[model]\n",
    "    y = ys_dict[model]\n",
    "    \n",
    "    coefficients = results_dict[model][\"params\"]\n",
    "    coefficients = coefficients[None, :]\n",
    "    weighted_features = X * coefficients\n",
    "    weighted_features = np.sum(weighted_features, axis=1)\n",
    "    \n",
    "    # average the ys at each class of weighted features from -0.5 to 0.5    \n",
    "    bins = np.linspace(-6.0, 6.0, 15)\n",
    "    bin_centers = (bins[1:] + bins[:-1])/2\n",
    "    \n",
    "    y_means = np.zeros_like(bin_centers)\n",
    "    y_stds = np.zeros_like(bin_centers)\n",
    "    \n",
    "    color = color_table[model]\n",
    "    alpha = 0.8\n",
    "    \n",
    "    for i in range(len(bins)-1):\n",
    "        mask = (weighted_features >= bins[i]) & (weighted_features < bins[i+1])\n",
    "        y_means[i] = np.mean(y[mask])\n",
    "        y_stds[i] = np.std(y[mask])\n",
    "        \n",
    "    # plt.errorbar(bin_centers + si/20, y_means, yerr=y_stds/np.sqrt(20), fmt='o', ls =\"-\", label=model+' T:'+str(temp))\n",
    "    plt.plot(bin_centers, y_means, marker='o', label=model, color=color, alpha=alpha)#, markersize=10) \n",
    "        \n",
    "    # find the indices of the bins with the highest and lowest non-nan values\n",
    "    max_value = np.nanmax(y_means)\n",
    "    min_value = np.nanmin(y_means)\n",
    "    max_index = np.nanargmax(y_means)\n",
    "    min_index = np.nanargmin(y_means)\n",
    "    \n",
    "    min_bin_index = bin_centers[0]\n",
    "    max_bin_index = bin_centers[-1]\n",
    "\n",
    "    # plot a dashed line from -6 to the min_value and from the max_value to 6\n",
    "    plt.plot([min_bin_index, bin_centers[min_index]], [min_value, min_value], 'k--', color = color, alpha=alpha)\n",
    "    plt.plot([bin_centers[max_index], max_bin_index], [max_value, max_value], 'k--', color = color, alpha=alpha)\n",
    "\n",
    "plt.legend(loc='lower right', ncols=1, columnspacing=0.1, labelspacing=0.3)#, fontsize=8)\n",
    "plt.xlabel('Pressure index')\n",
    "plt.ylabel('Average misalignment')\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "align_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
